{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5faf27ec-3a16-407e-bd86-4b89be7ebc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0ccf46a-96bd-4c45-b1bc-e2fff50e97c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/Data-Engineering-Zoomcamp/pipeline/.venv/lib/python3.13/site-packages/pandas/__init__.py'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm environment pandas is using/imported from.\n",
    "# our venv\n",
    "pd.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c7b2d49-62d5-41cf-9c98-66e87aad0603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49344/2399039197.py:6: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(url)\n"
     ]
    }
   ],
   "source": [
    "# readability\n",
    "prefix = 'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/'\n",
    "url = f'{prefix}/yellow_tripdata_2021-01.csv.gz'\n",
    "\n",
    "# Read a sample of the data\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cae284-ea3d-41bb-a69e-0138fa38f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73da4989-9622-4e1d-8370-d675056db7b7",
   "metadata": {},
   "source": [
    "###### To prevent type issue, clean data type on load as opposed to after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89c1b337-148d-40a9-a0e5-43188eca4bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data type on load\n",
    "dtype = {\n",
    "    \"VendorID\": \"Int64\",\n",
    "    \"passenger_count\": \"Int64\",\n",
    "    \"trip_distance\": \"float64\",\n",
    "    \"RatecodeID\": \"Int64\",\n",
    "    \"store_and_fwd_flag\": \"string\",\n",
    "    \"PULocationID\": \"Int64\",\n",
    "    \"DOLocationID\": \"Int64\",\n",
    "    \"payment_type\": \"Int64\",\n",
    "    \"fare_amount\": \"float64\",\n",
    "    \"extra\": \"float64\",\n",
    "    \"mta_tax\": \"float64\",\n",
    "    \"tip_amount\": \"float64\",\n",
    "    \"tolls_amount\": \"float64\",\n",
    "    \"improvement_surcharge\": \"float64\",\n",
    "    \"total_amount\": \"float64\",\n",
    "    \"congestion_surcharge\": \"float64\"\n",
    "}\n",
    "\n",
    "# Parse dates\n",
    "parse_dates = [\n",
    "    \"tpep_pickup_datetime\",\n",
    "    \"tpep_dropoff_datetime\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fcdcdc9-780e-43ae-b7c1-16b82d4454bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a sample of the data\n",
    "df = pd.read_csv(url,\n",
    "                 dtype=dtype,\n",
    "                 parse_dates=parse_dates\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "befdd566-db24-4a8e-85d3-5264eb8d43a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                          Int64\n",
       "tpep_pickup_datetime     datetime64[ns]\n",
       "tpep_dropoff_datetime    datetime64[ns]\n",
       "passenger_count                   Int64\n",
       "trip_distance                   float64\n",
       "RatecodeID                        Int64\n",
       "store_and_fwd_flag       string[python]\n",
       "PULocationID                      Int64\n",
       "DOLocationID                      Int64\n",
       "payment_type                      Int64\n",
       "fare_amount                     float64\n",
       "extra                           float64\n",
       "mta_tax                         float64\n",
       "tip_amount                      float64\n",
       "tolls_amount                    float64\n",
       "improvement_surcharge           float64\n",
       "total_amount                    float64\n",
       "congestion_surcharge            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5feca17-298e-414b-bd8b-3fbd8221f6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 18)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f4ca619-1fa3-45c8-9ef0-90b26cb748b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m119 packages\u001b[0m \u001b[2min 0.57ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m11 packages\u001b[0m \u001b[2min 0.13ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install connector to database\n",
    "!uv add sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4894154-dd7e-4572-8bf6-9da50b2a3f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m119 packages\u001b[0m \u001b[2min 0.76ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m11 packages\u001b[0m \u001b[2min 0.19ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# we install binary version as that is faster\n",
    "!uv add psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7bcf168-5544-431b-9e58-37041fa2e33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m120 packages\u001b[0m \u001b[2min 0.70ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m12 packages\u001b[0m \u001b[2min 0.21ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install tqdm to help monitor progress\n",
    "!uv add tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f122d1c1-32ae-4a35-a19c-67e86efae232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our downloaded database connector\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# create connection\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8abafd5-7868-4ccf-b594-4e8642b4b58e",
   "metadata": {},
   "source": [
    "###### Now we can use `df.sql` to insert into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "acc72118-d0b4-4332-b606-9460bc16f6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE yellow_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how does this get the schema\n",
    "print(pd.io.sql.get_schema(df, name='yellow_taxi_data', con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c6ea951-40f0-4833-8c80-2a920c3d4237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just create table with schema or column_names\n",
    "# it actually adds it to our dockerized database/postgres\n",
    "df.head(0).to_sql(name='yellow_taxi_data', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d674cf67-c096-464e-914e-94b8a9792e9b",
   "metadata": {},
   "source": [
    "###### (MONITORED) INGESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "50f458f6-ce8c-446a-b634-d640ab4c1305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create iterators instead of dataframes\n",
    "df_iter = pd.read_csv(url,\n",
    "                      dtype=dtype,\n",
    "                      parse_dates=parse_dates,\n",
    "                      iterator= True,\n",
    "                      chunksize= 100000\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "421b435d-5198-46b3-9e05-2a86e5459be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helps monitor progress\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5f51ff18-2987-42f5-b9f4-3387062a58b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa30ed4b46b2422da8e1b74d0f6f282b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# actual ingestion script\n",
    "# load and monitor in batches\n",
    "for chunk_df in tqdm(df_iter):\n",
    "    chunk_df.to_sql(name='yellow_taxi_data', \n",
    "                    con=engine, \n",
    "                    if_exists='append')\n",
    "\n",
    "    print(\"Inserted chunk:\", len(chunk_df))\n",
    "\n",
    "# what if i wanted to make it such that it doesn't ingest data it has loaded before in case of retries\n",
    "# basically one of ACID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd5cca-a932-43a7-9f08-286a58c85c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
